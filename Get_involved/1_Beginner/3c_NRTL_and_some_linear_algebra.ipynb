{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The Non Random Two Liquids (NRTL) model for *excess Gibbs energy* ($g^E$) and a case study of the Liquid-Liquid equilibria of water+ethanol+ethyl acetate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Non Random Two Liquids (NRTL) model\n",
    "\n",
    "Calculates excess Gibbs energy and its derivatives: e.g. activity coefficients $\\underline{\\gamma}$ and excess molar enthalpy $h^E$ at given $T$, $P$ and composition $\\underline {x}$ for a liquid mixture.\n",
    "\n",
    "\n",
    "## Model overview\n",
    "\n",
    "\n",
    "$$ \\frac{g^E}{RT}=\\sum_{i=1}^n \\left[ x_i\\frac{\\sum_{j=1}^n \\left[ \\tau_{j,i} G_{j,i} x_{j} \\right] }{\\sum_{k=1}^n \\left[ G_{k,i} x_k \\right] } \\right] $$\n",
    "\n",
    "Where\n",
    "\n",
    "> $\\tau_{i,j}= \\frac{g_{i,j}-g_{j,j}}{RT}=\\frac{A_{i,j}}{T}$\n",
    ">\n",
    "> $G_{i,j}=\\mathrm{exp}(-\\alpha_{i,j} \\tau_{i,j})$\n",
    "\n",
    "And either each $(g_{i,j}-g_{j,j})$ difference, in units of energy, or  each $A_{i,j}$ binary parameter, in units of temperature, are usually fitted to experimental data and published.\n",
    "\n",
    "The activities coefficients are calculated from the derivative of excess gibbs energy with respect to mole number of componente i ($n_i=N x_i$) with T, P and mole number of every other component held constant, ($RTln(\\gamma_i) = {\\partial g^E}/{ \\partial n_i}$)therefore:\n",
    "\n",
    "\n",
    "$$ln(\\gamma_i)=  \\frac{\\sum_{j=1}^n\\left[\\tau_{j,i} G_{j,i} x_{j}\\right]}{\\sum_{k=1}^n\\left[G_{k,i}x_{k}\\right]} + \\sum_{j=1}^n\\left[ \\left(\\frac{\\ G_{i,j} x_{j}}{\\sum_{k=1}^n\\left[G_{k,j}x_{k}\\right]}\\right) \\left(\\tau_{i,j}-\\frac{\\sum_{k=1}^n\\left[\\tau_{k,i} G_{k,i} x_{k}\\right]}{\\sum_{k=1}^n\\left[G_{k,j}x_{k}\\right]} \\right) \\right] $$\n",
    "\n",
    "## References:\n",
    "\n",
    "### The NRTL model' original paper\n",
    "* Renon H., Prausnitz J. M., Local Compositions in Thermodynamic Excess Functions for Liquid Mixtures, AIChE J., 14_1, S.135â€“144, 1968 [doi:10.1002/aic.690140124](https://doi.org/10.1002/aic.690140124)\n",
    "\n",
    "\n",
    "\n",
    "### The NRTL model in some books\n",
    "* Prausnitz, Lichtenthaler & Azevedo, Molecular Thermodynamic of Fluid Phase Equilibria, 1998 [ISBN-10: 0139777458](https://books.google.com.br/books?id=VSwc1XUmYpcC)\n",
    "\n",
    "### More papers on the NRTL model\n",
    "* Abreu, C. R. A., Matrix Algebra and Matrix Differentiation Rules Applied to Excess Gibbs Energy Models, Lecture notes available [here][Abreu, yyyy, LN, Matrix algebra...].\n",
    "\n",
    "[Abreu, yyyy, LN, Matrix algebra...]: https://github.com/iurisegtovich/PyTherm-applied-thermodynamics/blob/master/Get_involved/4_Texts_Library/AbreuC.R.A.%2C%20Matrix%20Algebra%20and%20Matrix%20Differentiation%20Rules%20Applied%20to%20Excess%20Gibbs%20Energy%20Models.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting the computational implementation of the model:\n",
    "\n",
    "Gather the needed packages here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inputs\n",
    "\n",
    "Experimental parameters from Renon et al., (1969)\n",
    "\n",
    "### References:\n",
    "\n",
    "Renon, Henri, and J. M. Prausnitz. \"Estimation of parameters for the NRTL equation for excess Gibbs energies of strongly nonideal liquid mixtures.\" Industrial & Engineering Chemistry Process Design and Development 8.3 (1969): 413-419.\n",
    "[DOI:10.1021/i260031a019]( https://doi.org/10.1021/i260031a019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thermodynamics *degrees of freedom*\n",
    "Excess gibbs energy, and activity coefficients are natural functions of temperature $(T)$, pressure $(P)$ and composition $(\\underline{x})$.\n",
    "Here, we will consider the system studied by Renon et al. (1969), they regressed parameters with which the model is valid for constant pressure of 1 atm.\n",
    "The remaining thermodynamics *degrees of freedom* required to calculate a set of activity coefficients are the temperature and composition.\n",
    "We set trial values below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trial temperature and composition:\n",
    "T = 293.15 #K\n",
    "x=np.array([.1,.3,.6]) #normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted parameters\n",
    "Renon et al. (1969) fitted 1 $\\alpha$ valid for all 3 binary interactions $\\{(1,2),(1,3),(2,3)\\}$ parameter and 6 $A_{i,j}$ parameters, two for each binary interaction filling a non symmetric $A$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ethyl acetate (1) + water (2) + ethanol (3)\n",
    "\n",
    "\n",
    "alpha12 = 0.4\n",
    "\n",
    "alpha23 = 0.3\n",
    "\n",
    "alpha13 = 0.3\n",
    "\n",
    "# 6 binary Aij parameters\n",
    "Dg12 = 1335 #K\n",
    "Dg21 = 2510 #K\n",
    "\n",
    "Dg23 = 976 #K\n",
    "Dg32 = 88 #K\n",
    "\n",
    "Dg13 = 301 #K\n",
    "Dg31 = 322 #K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feeding the fitted parameters to the model in matrix structure:\n",
    "we will assemble the parameters in a matrix structure so that we can access each parameter by its index, as in\n",
    "`A[0,0]` and `A[0,1]`rather than as `A11` and `A12`, so we can loop trough all of them using an iterator, see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#assemble matrix with regressed parameters Dg_i,j, according to the model all diagonal terms are zero\n",
    "Dg = np.array([[0, Dg12, Dg13],\n",
    "             [Dg21, 0, Dg23],\n",
    "             [Dg31, Dg32, 0]])\n",
    "\n",
    "A = Dg/R\n",
    "\n",
    "#assemble symmetric matrix alpha\n",
    "alpha = np.array([[0, alpha12, alpha13],\n",
    "                [alpha12, 0, alpha23],\n",
    "                [alpha13, alpha23, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i,j,alpha[i,j],A[i,j]\n",
      "0 0 0.0 0.0\n",
      "0 1 0.4 160.572528266\n",
      "0 2 0.3 36.2039932644\n",
      "1 0 0.4 301.900408949\n",
      "1 1 0.0 0.0\n",
      "1 2 0.3 117.392350253\n",
      "2 0 0.3 38.7298532596\n",
      "2 1 0.3 10.5845561703\n",
      "2 2 0.0 0.0\n",
      "alpha=\n",
      "[[ 0.   0.4  0.3]\n",
      " [ 0.4  0.   0.3]\n",
      " [ 0.3  0.3  0. ]]\n",
      "A=\n",
      "[[   0.          160.57252827   36.20399326]\n",
      " [ 301.90040895    0.          117.39235025]\n",
      " [  38.72985326   10.58455617    0.        ]]\n",
      "alpha12,alpha13,alpha23\n",
      "0.4 0.3 0.3\n",
      "A12,A13,A21,A23,A31,A32\n",
      "107.99 1011.98 555.81 -1113.1 2277.37 1217.37\n"
     ]
    }
   ],
   "source": [
    "#verify the assembled matrices\n",
    "\n",
    "#we can now automatically loop through its elements\n",
    "\n",
    "print(\"i,j,alpha[i,j],A[i,j]\")\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        print(i,j,alpha[i,j],A[i,j])\n",
    "        \n",
    "#or even use the whole matrix at once\n",
    "print(\"alpha=\")\n",
    "print(alpha)\n",
    "print(\"A=\")\n",
    "print(A)\n",
    "\n",
    "\n",
    "# rather than typing each element indiividually\n",
    "print(\"alpha12,alpha13,alpha23\")\n",
    "print(alpha12,alpha13,alpha23)\n",
    "print(\"A12,A13,A21,A23,A31,A32\")\n",
    "print(A12,A13,A21,A23,A31,A32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model equations\n",
    "We first implement the model equations in a script-wise manner, considering the models input - the regressed parameters and thermodynamic degrees of freedom previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau=\n",
      "[[ 0.          0.54774869  0.12349989]\n",
      " [ 1.0298496   0.          0.40045148]\n",
      " [ 0.13211616  0.03610628  0.        ]]\n",
      "G=\n",
      "[[ 1.          0.80324181  0.96362798]\n",
      " [ 0.66236412  1.          0.88680032]\n",
      " [ 0.96114034  0.98922657  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "tau=np.zeros([3,3])\n",
    "for j in range(3):\n",
    "    for i in range(3):\n",
    "        tau[j,i]=A[j,i]/T\n",
    "print(\"tau=\")\n",
    "print(tau)\n",
    "        \n",
    "G=np.zeros([3,3])\n",
    "for j in range(3):\n",
    "    for i in range(3):\n",
    "        G[j,i]=np.exp((-alpha[j,i]*tau[j,i]))\n",
    "print(\"G=\")\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.49680164  1.28852206  1.01628464]\n"
     ]
    }
   ],
   "source": [
    "Gamma=np.zeros([3])\n",
    "for i in range(3):\n",
    "\n",
    "    Sj1=0\n",
    "    Sj2=0\n",
    "    Sj3=0\n",
    "    for j in range(3):\n",
    "        Sj1     += tau[j,i]*G[j,i]*x[j]\n",
    "        Sj2     += G[j,i]*x[j]\n",
    "\n",
    "        Sk1=0\n",
    "        Sk2=0\n",
    "        Sk3=0\n",
    "        for k in range(3):\n",
    "            Sk1+=G[k,j]*x[k]\n",
    "            Sk2+=x[k]*tau[k,j]*G[k,j]\n",
    "            Sk3+=G[k,j]*x[k]\n",
    "        \n",
    "        Sj3     += ((x[j]*G[i,j])/(Sk1))*(tau[i,j]-(Sk2)/(Sk3))\n",
    "    \n",
    "    Gamma[i]=np.exp(Sj1/Sj2 + Sj3)\n",
    "    \n",
    "print(Gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Functionize* the model\n",
    "\n",
    "> \"taking a block of code and converting it into a function that can be inherited (or included once) and called by various other programs sometimes over and over again.\" -[functionize](http://www.urbandictionary.com/define.php?term=functionize)\n",
    "\n",
    "In order for us to be able to re-use this model in different works we would like to functionize it, so we could call this function with different parameters and thermodynamic conditions, and with that make recursive usage to:\n",
    "* create plots for a given system - varying x and T\n",
    "* find solutions in phase equilibrium algorithms - varying x and T\n",
    "* study different systems - varying component-dependent parameters\n",
    "* perform parameter regression - varying parameter values to correlate data for a given system\n",
    "\n",
    "$$\\underline{\\gamma} \\leftarrow {\\gamma} \\left(T,\\underline {x}, \\underline {\\underline{\\alpha}}, \\underline {\\underline{\\tau}}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def model(arguments):\n",
    "Functionizing the model is straightforward: we just copy the expressions already presented in the script-wise approach\n",
    "and then wrap them in a `def` block with clear inputs:\n",
    "\n",
    "    def Gamma(T,x,alpha,A):\n",
    "\n",
    "and clear outputs:\n",
    "\n",
    "    return Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Gamma(T,x,alpha,AA):\n",
    "    tau=np.zeros([3,3])\n",
    "    for j in range(3):\n",
    "        for i in range(3):\n",
    "            tau[j,i]=A[j,i]/T    \n",
    "    \n",
    "    G=np.zeros([3,3])\n",
    "    for j in range(3):\n",
    "        for i in range(3):\n",
    "            G[j,i]=np.exp((-alpha[j,i]*tau[j,i]))\n",
    "    \n",
    "    Gamma=np.zeros([3])\n",
    "    for i in range(3):\n",
    "\n",
    "        Sj1=0\n",
    "        Sj2=0\n",
    "        Sj3=0\n",
    "        for j in range(3):\n",
    "            Sj1 += tau[j,i]*G[j,i]*x[j]\n",
    "            Sj2 += G[j,i]*x[j]\n",
    "    \n",
    "            Sk1=0\n",
    "            Sk2=0\n",
    "            Sk3=0\n",
    "            for k in range(3):\n",
    "                Sk1 += G[k,j]*x[k]\n",
    "                Sk2 += x[k]*tau[k,j]*G[k,j]\n",
    "                Sk3 += G[k,j]*x[k]\n",
    "            \n",
    "            Sj3 += ((x[j]*G[i,j])/(Sk1))*(tau[i,j]-(Sk2)/(Sk3))\n",
    "        \n",
    "        Gamma[i]=np.exp(Sj1/Sj2 + Sj3)\n",
    "    \n",
    "    return Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.49680164  1.28852206  1.01628464]\n"
     ]
    }
   ],
   "source": [
    "#test it to see if results match\n",
    "ans=Gamma(T,x,alpha,A)\n",
    "print(ans) #ttest using those trial input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in ~pure Ethyl acetate liquid, Ethyl acetate's itself activity coefficient is  1.0\n",
      "ethanol infinite dillution activity coefficient is  1.28464455007\n",
      "and water infinite dillution activity coefficient is  3.42083308792\n",
      "in ~pure ethanol liquid, ethanol's itself activity coefficient is  1.54676981851\n",
      "Ethyl acetate infinite dillution activity coefficient is  4.34847080764\n",
      "and water infinite dillution activity coefficient is  1.0\n",
      "in ~pure water liquid, water's itself activity coefficient is  1.47879383184\n",
      "ethanol infinite dillution activity coefficient is  1.0\n",
      "and Ethyl acetate infinite dillution activity coefficient is  1.28546962045\n"
     ]
    }
   ],
   "source": [
    "# test predictions of activity coefficients at infinite dillution\n",
    "ans=Gamma(T,[1,0,0],alpha,A)\n",
    "print(\"in ~pure Ethyl acetate liquid, Ethyl acetate's itself activity coefficient is \",ans[0])\n",
    "print(\"ethanol infinite dillution activity coefficient is \", ans[2])\n",
    "print(\"and water infinite dillution activity coefficient is \", ans[1])\n",
    "\n",
    "ans=Gamma(T,[0,1,0],alpha,A)\n",
    "\n",
    "print(\"in ~pure ethanol liquid, ethanol's itself activity coefficient is \",ans[2])\n",
    "print(\"Ethyl acetate infinite dillution activity coefficient is \", ans[0])\n",
    "print(\"and water infinite dillution activity coefficient is \", ans[1])\n",
    "\n",
    "ans=Gamma(T,[0,0,1],alpha,A)\n",
    "\n",
    "print(\"in ~pure water liquid, water's itself activity coefficient is \",ans[1])\n",
    "print(\"ethanol infinite dillution activity coefficient is \", ans[2])\n",
    "print(\"and Ethyl acetate infinite dillution activity coefficient is \", ans[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a first graphical result we can plot the Excess Gibbs energy as a function of mole fraction of one component ina  binary mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAFkCAYAAABxWwLDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa0444440b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T=298\n",
    "xW=np.linspace(0,1,100)\n",
    "xE=1-xW\n",
    "Ge=np.zeros(100)\n",
    "R=8.314\n",
    "\n",
    "for i in range(100):\n",
    "    gammas=Gamma(T,[0,xE[i],xW[i]],alpha,A)\n",
    "    Ge[i]=(R*T*(xE[i]*np.log(gammas[1])+xW[i]*np.log(gammas[2])))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(xE,Ge)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying linear algebra matrix notation\n",
    "\n",
    "This implementation can be rewritten using linear algebra matrix notation, this can simplify analytical derivations, improve readability (although for the trained mind), maintainability, reduce human error in the coding (less typing therefore less typos), and improve execution speed (if we make use of libraries that can automatically convert matrix notation to optimal implementation of the underlying loops - e.g. NumPy).\n",
    "For details on the derivations of the matrix notation for the NRTL model, as well as for UNIQUAC, UNIFAC and COSMO see the lectures notes of Abreu, C. R. A. in our library [here][Abreu, yyyy, LN, Matrix algebra...].\n",
    "\n",
    "[Abreu, yyyy, LN, Matrix algebra...]: https://github.com/iurisegtovich/PyTherm-applied-thermodynamics/blob/master/Get_involved/4_Texts_Library/AbreuC.R.A.%2C%20Matrix%20Algebra%20and%20Matrix%20Differentiation%20Rules%20Applied%20to%20Excess%20Gibbs%20Energy%20Models.pdf\n",
    "\n",
    "| - - - - - - - - - - - - - - Renon & Prausnitz - - - - - - - - - - - - - - | - - - - - - - - - - - - - - Abreu - - - - - - - - - - - - - - |\n",
    "|:-:|:-:|\n",
    "|$ \\frac{g^E}{RT}=\\sum_{i=1}^n \\left[ x_i\\frac{\\sum_{j=1}^n \\tau_{j,i} G_{j,i} x_{j}}{\\sum_{k=1}^n G_{k,i} x_k} \\right] $|$ \\frac{g^E}{RT}=\\underline{x}^T\\underline{\\underline{E}} \\underline{x}$ |\n",
    "\n",
    "Where\n",
    "\n",
    "| - - - - - - - - - - - - - - Renon & Prausnitz - - - - - - - - - - - - - - | - - - - - - - - - - - - - - Abreu - - - - - - - - - - - - - - |\n",
    "|:-:|:-:|\n",
    "|$\\tau_{i,j}= \\frac{g_{i,j}-g_{j,j}}{RT}=\\frac{A_{i,j}}{T}$ | $\\underline{\\underline{\\tau}}=-T^{-1}\\underline{\\underline{A}}$|\n",
    "|$G_{i,j}=\\mathrm{exp}(-\\alpha_{i,j} \\tau_{i,j})$|$\\underline{\\underline{G}}= \\mathrm{exp}(\\underline{\\underline{\\alpha}} \\circ \\underline{\\underline{\\tau}})$|\n",
    "|---|$\\underline{\\underline{\\Lambda}}=(\\underline{\\underline{\\tau}} \\circ \\underline{\\underline{G}})$|\n",
    "|---|$\\underline{\\underline{E}}=\\underline{\\underline{\\Lambda}}\\mathscr{D}^{-1}(\\underline{\\underline{G}}^T\\underline{x})$|\n",
    "\n",
    "Therefore\n",
    "\n",
    "\n",
    "| - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Renon & Prausnitz - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - | - - - - - - - - - - - Abreu - - - - - - - - - - - |\n",
    "|:-:|:-:|\n",
    "|$ln(\\gamma_i)=  \\frac{\\sum_{j=1}^n\\left[\\tau_{j,i} G_{j,i} x_{j}\\right]}{\\sum_{k=1}^n\\left[G_{k,i}x_{k}\\right]} + \\sum_{j=1}^n\\left[ \\left(\\frac{\\ G_{i,j} x_{j}}{\\sum_{k=1}^n\\left[G_{k,j}x_{k}\\right]}\\right) \\left(\\tau_{i,j}-\\frac{\\sum_{j=1}^n\\left[\\tau_{i,j} G_{i,j} x_{i}\\right]}{\\sum_{k=1}^n\\left[G_{k,j}x_{k}\\right]} \\right) \\right] $|$ ln(\\underline{\\gamma})=\\left(\\underline{\\underline{E}}^S-\\underline{\\underline{L}}\\mathscr{D}\\underline{x}\\underline{\\underline{E}}^T \\right)\\underline{x}$|\n",
    "\n",
    "Where\n",
    "\n",
    "* $\\underline{\\underline{M}} \\circ \\underline{\\underline{N}}$ is the Hadamard product, element-wise multiplication between matrices $\\underline{\\underline{M}} $and$ \\underline{\\underline{N}}$, i.e.,\n",
    "$$\\underline{\\underline{M}} \\circ \\underline{\\underline{N}} = \\left\\{ \\underline{\\underline{R}} \\mid R_{i,j}=M_{i,j} \\times N_{i,j} \\right\\}$$\n",
    "\n",
    "* $\\mathscr{D}\\underline{v}$ means matrix diagonalization of an column $\\underline{v}$, i.e.,\n",
    "$$\\mathscr{D}\\underline{v}= \\left\\{ \\underline{\\underline{M}} \\mid M_{i,j}=v_{i} \\text { if } {j = i} \\text{, and } M_{i,j} = 0 \\text { if } {j \\neq i} \\right\\}$$\n",
    "\n",
    "* $\\underline{\\underline{M}}^S$ means symmetrization of a matrix $\\underline{\\underline{M}}$, i.e.,\n",
    "$$\\underline{\\underline{M}}^S= \\left\\{ \\underline{\\underline{N}} \\mid N_{i,j}=M_{i,j}+M_{j,i}\\right\\}$$\n",
    "* $\\underline{\\underline{M}}^T$ means transposition of a matrix $\\underline{\\underline{M}}$, i.e.,\n",
    "$$\\underline{\\underline{M}}^T= \\left\\{ \\underline{\\underline{N}} \\mid N_{i,j}=M_{j,i} \\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **matrix multiplication**\n",
    "\n",
    "> Replace summations of matrices in one of its dimensions\n",
    "\n",
    "  * elemental definition:\n",
    "\n",
    "$C_{i,j} = \\sum_k{\\left[A_{i,k} \\times B_{k,j}\\right]}$\n",
    "\n",
    "$d_{i} = \\sum_k{\\left[A_{i,k} \\times b_{k}\\right]}$\n",
    "\n",
    "$e_{j} = \\sum_k{\\left[a_{k} \\times B_{k,j}\\right]}$\n",
    "\n",
    "  * matrix notation\n",
    "\n",
    "$\\underline{\\underline{C}}=\\underline{\\underline{A}}\\underline{\\underline{B}}$\n",
    "\n",
    "$\\underline{d}=\\underline{\\underline{A}}\\underline{b}$\n",
    "\n",
    "$\\underline{e}=(\\underline{a^T}\\underline{\\underline{B}})^T$\n",
    "\n",
    "\n",
    "  * python implementation\n",
    "\n",
    "`C = A @ B`\n",
    "\n",
    "`d = A @ b`\n",
    "\n",
    "`e = (a.T @ B).T`\n",
    "\n",
    "* **element-wise multiplication**\n",
    "\n",
    "> Condensate operations that apply analogously in all elements of one or more matrices\n",
    "\n",
    "  * elemental definition:\n",
    "\n",
    "$C_{i,j} = A_{i,j} \\times B_{i,j}$\n",
    "\n",
    "  * matrix notation\n",
    "\n",
    "$\\underline{\\underline{C}}=\\underline{\\underline{A}} \\circ \\underline{\\underline{B}}$\n",
    "\n",
    "  * python implementation\n",
    "\n",
    "`C = A * B`\n",
    "\n",
    "* **element-wise multiplication with broadcasting**\n",
    "\n",
    "> Diagonalization is used to represent element-wise multiplication between: two single line matrixes, two single columns, one single line matrix and each line of a (nl,nc) matrix, or one single column matrix and each column of a (nl,nc) matrix. This is useful in analytical differentiation presented in the lecture notes of [Abreu C. R. A.][Abreu, yyyy, LN, Matrix algebra...].\n",
    "On the other hand, this notation may be dropped later, at implementation time, for a numerical solution, depending on the programming enviroment, see below the usage and correspondence of notations:\n",
    "\n",
    "[Abreu, yyyy, LN, Matrix algebra...]: https://github.com/iurisegtovich/PyTherm-applied-thermodynamics/blob/master/Get_involved/4_Texts_Library/AbreuC.R.A.%2C%20Matrix%20Algebra%20and%20Matrix%20Differentiation%20Rules%20Applied%20to%20Excess%20Gibbs%20Energy%20Models.pdf\n",
    "\n",
    "  * elemental definition:\n",
    "\n",
    "$C_{i,j} = A_{i,j} \\times b_{j}$\n",
    "\n",
    "$D_{i,j} = b_{i} \\times A_{i,j}$\n",
    "\n",
    "$e_{i} = a_{i} \\times b_{i}$\n",
    "\n",
    "$f_{j} = b_{j} \\times a_{j}  $\n",
    "\n",
    "  * matrix notation\n",
    "\n",
    "$\\underline{\\underline{C}}=\\underline{\\underline{A}} \\left( \\mathscr D \\underline{b} \\right )$\n",
    "\n",
    "$\\underline{\\underline{D}}= \\left( \\mathscr D \\underline{b} \\right ) \\underline{\\underline{A}}$\n",
    "\n",
    "$\\underline{e}= \\left( \\mathscr D \\underline{a} \\right ) \\underline{b}$\n",
    "\n",
    "$\\underline{f}=\\left( \\underline{b}^{T} \\left( \\mathscr D \\underline{a} \\right ) \\right)^T$\n",
    "\n",
    "  * python implementation\n",
    "\n",
    "`C = A * b.T`\n",
    "\n",
    "`D = b * A`\n",
    "\n",
    "`e = a * b`\n",
    "\n",
    "`f = (b.T * a.T).T`\n",
    "\n",
    "> where we chose to use:\n",
    ">- upper case letters to represent full (nl,nc) matrixes\n",
    ">- lower case letters to represent single column matrixes)\n",
    ">\n",
    "> while from Python/NumPy syntax:\n",
    ">- `M.T` is the numpy native syntax for transposition of a matrix `M`\n",
    ">- `A \\* B` is the numpy native syntax for the element-wise multiplication between matrixes `A` and `B`\n",
    "\n",
    "Note that in matrix algebra in python, single columns and single line matrixes should be represented by 2d arrays having shape (nl,1) and (1,nc), respectively. This is not quite the same thing as 1d arrays. Understand the differences seeing usage examples [here][Lists and array operations].\n",
    "\n",
    "> where:\n",
    ">- nl stands for number of lines in a single column (nl,1) matrix or in a full (nl,nc) matrix\n",
    ">- nc stands for number of columns in a single line (1,nc) matrix or in a full (nl,nc) matrix\n",
    "\n",
    "[Lists and array operations]: http://localhost:8888/notebooks/LocalWorkspaces/Pytherm/GITSYNC/Get_involved/5_Syntax_cheat_sheets%2C_examples%2C_samples%2C_tests/List%20and%20Array%20operations.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use linear algebra in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Gamma_linalg(T,c_x,q_alpha, q_A): # here we chose to use the starting letters s, c, l, and Q to identify scalar variables, single column matrixes, single line matrixes and square matrixes to the reader\n",
    "    # e_T should be an scalar value for temperature\n",
    "    # c_x should be a single-column matrix(2d array) representing composition\n",
    "    # q_alpha should be two matrix(2d array) representing component dependent parameters inferred from experimental data\n",
    "    # q_tau should be two matrix(2d array) representing component dependent parameters inferred from experimental data\n",
    "    \n",
    "    q_tau     = q_A/T #element-wise division by scalar\n",
    "    q_at      = q_alpha*q_tau #M2d * N2d yields element-wise multiplication\n",
    "    q_minusat     = -q_at #element wise signal change\n",
    "    q_G       = np.exp(q_minusat) #element wise exponentiation\n",
    "    q_Lambda  = (q_tau*q_G) #element-wise multiplication\n",
    "    q_GT      = q_G.T #M.T yields the transpose matrix of M;\n",
    "    c_den     = q_GT @ c_x #M @ N yields the matrix multiplication between M and N\n",
    "    c_invden  = 1/c_den #scalar 1 is broadcast for element-wise division\n",
    "    l_invden  = c_invden.T #transposition of a single column matrix yields a single line matrix\n",
    "    q_E       = q_Lambda * l_invden #element wise multiplication between (nl,nc) matrix M with (1,nc) matrix l broadcasts the element-wise multiplication of each (1,nc) submatrix of M with the unique (1,nc) matrix l\n",
    "    q_L       = q_G * l_invden #broadcasting of element-wise multiplication\n",
    "    l_x       = c_x.T #transposition of a single column matrix yields a single line matrix\n",
    "    q_Lx      = q_L * l_x #broadcasting of element-wise multiplication\n",
    "    q_ET      = q_E.T #transposition of square matrix\n",
    "    q_LxET    = q_Lx @ q_ET #matrix multiplication\n",
    "    q_ES      = q_E+q_ET #element-wise sum\n",
    "    q_ESminusLxET = q_ES-q_LxET #element-wise subtraction\n",
    "    q_ESminusLxETx     = q_ESminusLxET @ c_x #matrix multiplication\n",
    "    gamma     = np.exp(q_ESminusLxETx) #element-wise exponentiation\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.48877982]\n",
      " [ 1.28373249]\n",
      " [ 1.01599751]]\n"
     ]
    }
   ],
   "source": [
    "#a test case for the function\n",
    "#where x was the composition represented in a 1d array\n",
    "#and now line and x_as_column is a single lne and a single column matrix, respectively to represent composition\n",
    "#We build it using the array function to wrap the 1d array in another 1d aray, hence a 2d array\n",
    "x_as_line = np.array([x])\n",
    "#We transpose x_as_line to creata x_as_column, which is the shape expected by the linalgGamma function\n",
    "x_as_column = np.array([x]).T #we wrap x with an extra braket so it is now a 2d array, a matrix, as we did not add any extra lines it is a single-line matrix, we tranpose to generate a single-column matrix (1d arrays cannot be transposed, there is no second dimension)\n",
    "#print the output to see if errors occur and if values are coherent(between zero and infinity, tending to 1 for ideal solutions)\n",
    "print(Gamma_linalg(T,x_as_column,alpha,A)) #test using those trial input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Gamma_linalg_tiny(T,c_x,q_alpha, q_A):\n",
    "    #note that we used many lines for didatics\n",
    "    #we can do it in few lines:\n",
    "    #note that some expression occur more than once below\n",
    "    #so it may be useful define it as a intermediary recurrent term here\n",
    "    #and calculate it once to use it then several times\n",
    "    q_tau     = q_A/T\n",
    "    q_G       = np.exp(-(q_alpha*q_tau))\n",
    "    l_D       = ((1/((q_G.T) @ c_x)).T)\n",
    "    q_E       = (q_tau*q_G) * l_D \n",
    "    gamma     = np.exp(((q_E+(q_E.T))-(((q_G * l_D) * (c_x.T)) @ (q_E.T))) @ c_x)\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.48877982]\n",
      " [ 1.28373249]\n",
      " [ 1.01599751]]\n"
     ]
    }
   ],
   "source": [
    "#test it to see that the results are the same\n",
    "print(Gamma_linalg_tiny(T,x_as_column,alpha,A)) #test using those trial input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What difference does it make?\n",
    "\n",
    "Ipython provides a profiling tool, with %timeit you can evaluate the time for execution of a line of program (with all called dependencies). In the following cells, we use it to evaluate our function in version 1 with explicit for loops and in version 2a and 2b with linear algebra matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 135 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit Gamma(T,x,alpha,A) #ttest using those trial input #My result was 90 micro seconds per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 250.18 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 28.5 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit Gamma_linalg(T,x_as_column,alpha,A) #ttest using those trial input #My result was 25 micro seconds per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 155.03 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 29.3 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit Gamma_linalg_tiny(T,x_as_column,alpha,A) #ttest using those trial input #My result was 25 micro seconds per loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here more honest trials with random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 2798.41 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 21.5 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "#approximately time the random number generation to subtract later\n",
    "# ~21 micro seconds per loop here\n",
    "N=3\n",
    "x=np.random.rand(N,1)\n",
    "x=x/sum(x)\n",
    "alpha=np.random.rand(N,N)\n",
    "A=np.random.rand(N,N)\n",
    "T=(np.random.rand(1,1)+.5)*273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 17.80 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 410 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# ~440 micro seconds per loop here (420 subtracting the random number generation)\n",
    "N=3\n",
    "x=np.random.rand(N,1)\n",
    "x=x/sum(x)\n",
    "alpha=np.random.rand(N,N)\n",
    "A=np.random.rand(N,N)\n",
    "T=(np.random.rand(1,1)+.5)*273\n",
    "\n",
    "_=Gamma(\n",
    "    T,\n",
    "    x,\n",
    "    alpha,\n",
    "    A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 89.87 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 56 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# ~56 micro seconds per loop here  (36 subtracting the random number generation)\n",
    "N=3\n",
    "x=np.random.rand(N,1)\n",
    "x=x/sum(x)\n",
    "alpha=np.random.rand(N,N)\n",
    "A=np.random.rand(N,N)\n",
    "T=(np.random.rand(1,1)+.5)*273\n",
    "\n",
    "_=Gamma_linalg(\n",
    "    T,\n",
    "    x,\n",
    "    alpha,\n",
    "    A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 147.78 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 57.3 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# ~52 micro seconds per loop here (32 subtracting the random number generation)\n",
    "N=3\n",
    "x=np.random.rand(N,1)\n",
    "x=x/sum(x)\n",
    "alpha=np.random.rand(N,N)\n",
    "A=np.random.rand(N,N)\n",
    "T=(np.random.rand(1,1)+.5)*273\n",
    "\n",
    "_=Gamma_linalg_tiny(\n",
    "    T,\n",
    "    x,\n",
    "    alpha,\n",
    "    A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maker it faster!\n",
    "Also, with minor effort, we can use Numba to further accelerate the code.\n",
    "\n",
    "See below how it is able to accelerate the functions `Gamma` `and Gamma_linalg_tiny` and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These two lines is all that it takes to accelerate this function\n",
    "from numba import jit\n",
    "@jit\n",
    "#now repeat the function with a different bname so we can compare\n",
    "def Gamma_numba(T,x,alpha,A):\n",
    "\n",
    "    tau=np.zeros([3,3])\n",
    "    for j in range(3):\n",
    "        for i in range(3):\n",
    "            tau[j,i]=A[j,i]/T    \n",
    "    \n",
    "    G=np.zeros([3,3])\n",
    "    for j in range(3):\n",
    "        for i in range(3):\n",
    "            G[j,i]=np.exp((-alpha[j,i]*tau[j,i]))\n",
    "    \n",
    "    Gamma=np.zeros([3])\n",
    "    for i in range(3):\n",
    "\n",
    "        Sj1=0\n",
    "        Sj2=0\n",
    "        Sj3=0\n",
    "        for j in range(3):\n",
    "            Sj1 += tau[j,i]*G[j,i]*x[j]\n",
    "            Sj2 += G[j,i]*x[j]\n",
    "    \n",
    "            Sk1=0\n",
    "            Sk2=0\n",
    "            Sk3=0\n",
    "            for k in range(3):\n",
    "                Sk1 += G[k,j]*x[k]\n",
    "                Sk2 += x[k]*tau[k,j]*G[k,j]\n",
    "                Sk3 += G[k,j]*x[k]\n",
    "            \n",
    "            Sj3 += ((x[j]*G[i,j])/(Sk1))*(tau[i,j]-(Sk2)/(Sk3))\n",
    "        \n",
    "        Gamma[i]=np.exp(Sj1/Sj2 + Sj3)\n",
    "    \n",
    "    return Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These two lines is all that it takes to accelerate this function\n",
    "from numba import jit\n",
    "@jit\n",
    "#now repeat the function with a different bname so we can compare\n",
    "def Gamma_linalg_tiny_numba(T,c_x,q_alpha, q_A):\n",
    "    #note that we used many lines for didatics\n",
    "    #we can do it one liner:\n",
    "    #note that some expression occur more than once below so it may be useful define it as a intermediary recurrent term here and calculate it once to use it then several times\n",
    "    q_tau     = q_A/T\n",
    "    q_G       = np.exp(-(q_alpha*q_tau))\n",
    "    l_D       = ((1/((q_G.T) @ c_x)).T)\n",
    "    q_E       = (q_tau*q_G) * l_D \n",
    "    gamma     = np.exp(((q_E+(q_E.T))-(((q_G * l_D) * (c_x.T)) @ (q_E.T))) @ c_x)\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4880.81 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 421 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# ~370 micro seconds per loop here (350 subtracting the random number generation, versus 420 thats not much acceleration)\n",
    "N=3\n",
    "x=np.random.rand(N,1)\n",
    "x=x/sum(x)\n",
    "alpha=np.random.rand(N,N)\n",
    "A=np.random.rand(N,N)\n",
    "T=(np.random.rand(1,1)+.5)*273\n",
    "\n",
    "_ = Gamma_numba(\n",
    "    T,\n",
    "    x,\n",
    "    alpha,\n",
    "    A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 10406.87 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 168 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# ~34 micro seconds per loop here (14 subtracting the random number generation, versus 32 thats approximately half)\n",
    "\n",
    "N=3\n",
    "x=np.random.rand(N,1)\n",
    "x=x/sum(x)\n",
    "alpha=np.random.rand(N,N)\n",
    "A=np.random.rand(N,N)\n",
    "T=(np.random.rand(1,1)+.5)*273\n",
    "\n",
    "_ = Gamma_linalg_tiny_numba(\n",
    "    T,\n",
    "    x,\n",
    "    alpha,\n",
    "    A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incoming features:\n",
    "\n",
    "* 3d plots of activity coefficient vs composition\n",
    ">- gamma1 vs (x1,x2 | x3=1-x1-x2)\n",
    ">- gamma2 vs (x1,x2 | x3=1-x1-x2)\n",
    ">- gamma3 vs (x1,x2 | x3=1-x1-x2)\n",
    "\n",
    "* Liq-Liq Equilibria flash algorithm\n",
    "\n",
    "* 2d x1-x2-x3 triangle plots of phase equilibria envelope at given T and P\n",
    "\n",
    "* Optimizing code with cython and numba, comparison with fortran and c\n",
    "\n",
    "* Problem inversion: Regression of alpha and tau parameters from experimental data."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
